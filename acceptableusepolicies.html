<!-- I have this conversation often. 

Person: “My company wants us to start using AI.”
Me: “Cool. Which one?”
Person: “They said that’s up to us. It’s just for efficiency.” 

And that’s the problem, right? Leadership and consulting loves to push ‘AI for efficiency’ and ‘if we’re not using it, we’re behind.’ But like most free tools, you’re the product. And it’s not exactly in your best interest to upload your client’s bank account number to the void. 

Thankfully, with proper licensing (ex. CoPilot EDP) and a little bit of prompt sanitizing, you’re in a better spot! What you need is an Acceptable Use Policy. Write down formal rules and parameters for your organization to follow. It’ll save you a lawsuit, and your IT department some sleep. 

AI Acceptable Use Policy 

Ideally, everyone in your organization should understand how Gen AI tools work before they use them in a corporate setting. 

Here’s the most important part: 

AI-powered conversational agents train their LLMs using user input. That’s especially true for free, non-enterprise versions. 
Most LLMs also have paid versions that are (according to their websites) contained to your company’s environment. 
Please use the contained versions. Especially if you’re in an industry that requires compliance to a GRC framework. Or in Europe.
Employees should know that all data they input can and will be used against them. 

I also highly recommend giving people guidelines on acceptable and prohibited use. 

Do not enter: 
Intellectual property. 
Company strategy. 
Legal documents. 
PII (personally identifiable information) - names, SSNs, client lists, license numbers, phone numbers, zip codes, home addresses. 
Date of birth, religion, and gender - less direct as social security numbers but they’re still identifiers. 
Credentials - MFA codes, usernames, passwords. 
Your security stack - Disclosing that you use Crowdstrike, Okta, Splunk, and LastPass gives attackers a blueprint on how to get in. cd .

If you’re not sure: 
Ask yourself if you’d put the information online. If you wouldn’t, don’t put it in ChatGPT.  -->
